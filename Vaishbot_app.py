import streamlit as st
import sounddevice as sd
import numpy as np
import queue
from scipy.io.wavfile import write
import requests
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from bs4 import BeautifulSoup
from datetime import datetime
from gtts import gTTS
import pygame
import os
import tempfile

# --- UI Setup ---
st.set_page_config(page_title="VaishBot", page_icon="ЁЯОУ")

# тЬЕ Use absolute path for avatar
IMAGE_PATH = r"D:\Vaishbot\avatar.jpg"
if os.path.exists(IMAGE_PATH):
    st.image(IMAGE_PATH, width=120)
else:
    st.warning("тЪая╕П avatar.jpg not found at the specified path.")

st.markdown("<h1 style='text-align:center;color:maroon;'>Welcome to VaishBot</h1>", unsafe_allow_html=True)

# --- Audio Playback with pygame ---
pygame.mixer.init()

def play_audio(file_path):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)
    # Delete the temp file after playback
    os.remove(file_path)

# --- Hybrid TTS with mkstemp ---
def speak(text, lang_code="en"):
    lang_map = {
        "ta": "ta", "hi": "hi", "en": "en", "te": "te", "ml": "ml",
        "kn": "kn", "gu": "gu", "or": "or", "ks": "ks", "raj": "raj"
    }
    # Create temp MP3 file
    fd, tmp_path = tempfile.mkstemp(suffix=".mp3")
    os.close(fd)  # Close so pygame can access
    tts = gTTS(text=text, lang=lang_map.get(lang_code, "en"))
    tts.save(tmp_path)
    play_audio(tmp_path)

# --- Silence-based Recording ---
def record_until_silence(fs=16000, silence_thresh=500, silence_duration=1.0):
    q = queue.Queue()

    def callback(indata, frames, time, status):
        if status:
            print(status)
        q.put(indata.copy())

    stream = sd.InputStream(samplerate=fs, channels=1, dtype='int16', callback=callback)
    audio_data = []
    silent_chunks = 0
    chunk_size = 1024
    chunks_per_sec = int(fs / chunk_size)

    with stream:
        st.info("ЁЯОЩ Speak now... stop when silent")
        while True:
            chunk = q.get()
            audio_data.append(chunk)
            volume = np.abs(chunk).mean()
            if volume < silence_thresh:
                silent_chunks += 1
            else:
                silent_chunks = 0
            if silent_chunks > silence_duration * chunks_per_sec:
                break

    audio = np.concatenate(audio_data, axis=0)
    return audio.flatten(), fs

def save_wav(filename, data, fs):
    write(filename, fs, data)

# --- ASR via Whisper API ---
def transcribe_whisper(audio_path, lang_code="en"):
    url = "http://localhost:8000/transcribe"
    with open(audio_path, "rb") as f:
        response = requests.post(url, files={"file": f})
    return response.json().get("text", "")

# --- Scrape Website ---
def scrape_sdnbvc():
    html = requests.get("https://sdnbvc.edu.in").text
    soup = BeautifulSoup(html, "html.parser")
    return " ".join([p.text for p in soup.find_all("p")])

# --- Match Answer ---
def find_answer(query, scraped_text):
    return query if query.lower() in scraped_text.lower() else "Sorry, I couldnтАЩt find an answer."

# --- Log Callback ---
def log_callback_request(user_query, phone_number, lang_code):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_name("service_account.json", scope)
    client = gspread.authorize(creds)
    sheet = client.open("VaishBot Callback Log").sheet1
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sheet.append_row([timestamp, lang_code, user_query, phone_number])

# --- Confirm Callback ---
def confirm_callback(lang_code):
    confirmation_text = {
        "ta": "роЙроЩрпНроХро│рпН роЕро┤рпИрокрпНрокрпБ роХрпЛро░ро┐роХрпНроХрпИ рокродро┐ро╡рпБ роЪрпЖропрпНропрокрпНрокроЯрпНроЯродрпБ. роОроЩрпНроХро│рпН роХрпБро┤рпБ ро╡ро┐ро░рпИро╡ро┐ро▓рпН родрпКроЯро░рпНрокрпБ роХрпКро│рпНроХро┐ро▒родрпБ.",
        "hi": "рдЖрдкрдХреА рдХреЙрд▓ рдмреИрдХ рдЕрдиреБрд░реЛрдз рджрд░реНрдЬ рдХрд░ рд▓реА рдЧрдИ рд╣реИред рд╣рдорд╛рд░реА рдЯреАрдо рдЬрд▓реНрдж рд╣реА рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдЧреАред",
        "en": "Your callback request has been logged. Our team will contact you soon.",
        "te": "р░ор▒А р░Хр░╛р░▓р▒НтАМр░мр▒Нр░пр░╛р░Хр▒Н р░Ер░нр▒Нр░пр░░р▒Нр░ер░и р░ир░ор▒Лр░жр▒Б р░Ър▒Зр░пр░мр░бр░┐р░Вр░жр░┐. р░ор░╛ р░мр▒Гр░Вр░жр░В р░др▒Нр░╡р░░р░▓р▒Л р░╕р░Вр░кр▒Нр░░р░жр░┐р░╕р▒Нр░др▒Бр░Вр░жр░┐.",
        "ml": "р┤ир┤┐р┤Щр╡Нр┤Щр┤│р╡Бр┤Яр╡Ж р┤Хр╡Лр╡╛р┤мр┤╛р┤Хр╡Нр┤Хр╡Н р┤Ер┤нр╡Нр┤пр╡╝р┤др╡Нр┤ер┤и р┤░р┤Ьр┤┐р┤╕р╡Нр┤▒р╡Нр┤▒р╡╝ р┤Ър╡Жр┤пр╡Нр┤др┤┐р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤ир╡Нр┤ир╡Б. р┤Юр┤Щр╡Нр┤Щр┤│р╡Бр┤Яр╡Ж р┤Яр╡Ар┤В р┤Йр┤Яр╡╗ р┤мр┤ир╡Нр┤зр┤кр╡Нр┤кр╡Жр┤Яр╡Бр┤В.",
        "kn": "р▓ир▓┐р▓ор│Нр▓о р▓Хр▓╛р▓▓р│НтАМр▓мр│Нр▓пр▓╛р▓Хр│Н р▓╡р▓┐р▓ир▓Вр▓др▓┐р▓пр▓ир│Нр▓ир│Б р▓жр▓╛р▓Цр▓▓р▓┐р▓╕р▓▓р▓╛р▓Чр▓┐р▓жр│Ж. р▓ир▓ор│Нр▓о р▓др▓Вр▓б р▓╢р│Ар▓Шр│Нр▓░р▓жр▓▓р│Нр▓▓р│З р▓╕р▓Вр▓кр▓░р│Нр▓Хр▓┐р▓╕р│Бр▓др│Нр▓др▓жр│Ж.",
        "gu": "ркдркорк╛рк░рлБркВ ркХрлЛрк▓ркмрлЗркХ рк╡рк┐ркиркВркдрлА ркирлЛркВркзрк╛ркИ ркЧркИ ркЫрлЗ. ркЕркорк╛рк░рлА ркЯрлАрко ркЯрлВркВркХ рк╕ркоркпркорк╛ркВ рк╕ркВрккрк░рлНркХ ркХрк░рк╢рлЗ.",
        "or": "рмЖрмкрмгрмЩрнНрмХрм░ рмХрм▓рнН рммрнНрнЯрм╛рмХрнН рмЕрмирнБрм░рнЛрмз рм░рнЗрмХрм░рнНрмб рм╣рнЛрмЗрмЫрм┐ред рмЖрмо рмЯрм┐рморнН рм╢рнАрмШрнНрм░ рмпрнЛрмЧрм╛рмпрнЛрмЧ рмХрм░рм┐рммрнЗред",
        "ks": "╪к┘П┘З┘Ж╪п ┌й╪з┘Д ╪и█М┌й ╪п╪▒╪о┘И╪з╪│╪к ╪п╪▒╪м ┌й█М ┌п╪ж█М █Б█Т█Ф █Б┘Е╪з╪▒╪з ╪╣┘Е┘Д█Б ╪м┘Д╪п ╪▒╪з╪и╪╖█Б ┌й╪▒█Т ┌п╪з█Ф",
        "raj": "рдерд╛рд░реЛ рдХреЙрд▓рдмреИрдХ рдЕрдиреБрд░реЛрдз рджрд░реНрдЬ рдХрд░рд┐рдпреЛ рдЧрдпреЛ рд╣реИред рд╣рдорд╛рд░реА рдЯреАрдо рдЬрд▓реНрдж рд╣реА рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдЧреАред"
    }
    speak(confirmation_text.get(lang_code, confirmation_text["en"]), lang_code)

# --- Language Selection ---
welcome_text = "Welcome to SDNB Vaishnav College. Please say your preferred language: Tamil, Hindi, Telugu, Malayalam, Kannada, Gujarati, Odia, Kashmiri, or Rajasthani."
speak(welcome_text, "en")

audio, fs = record_until_silence()
fd, tmp_path = tempfile.mkstemp(suffix=".wav")
os.close(fd)
save_wav(tmp_path, audio, fs)
lang_text = transcribe_whisper(tmp_path, "en").strip().lower()
os.remove(tmp_path)

language_map = {
    "tamil": "ta", "hindi": "hi", "telugu": "te", "malayalam": "ml",
    "kannada": "kn", "gujarati": "gu", "odia": "or", "kashmiri": "ks", "rajasthani": "raj"
}
lang_code = language_map.get(lang_text, "en")

confirm_text = {
    "ta": "роирпАроЩрпНроХро│рпН родрооро┐ро┤рпН родрпЗро░рпНроирпНродрпЖроЯрпБродрпНродрпБро│рпНро│рпАро░рпНроХро│рпН.",
    "hi": "рдЖрдкрдиреЗ рд╣рд┐рдВрджреА рдЪреБрдиреА рд╣реИред",
    "en": "You selected English.",
    "te": "р░ор▒Ар░░р▒Б р░др▒Жр░▓р▒Бр░Чр▒Б р░Ор░Вр░Ър▒Бр░Хр▒Бр░ир▒Нр░ир░╛р░░р▒Б.",
    "ml": "р┤ир┤┐р┤Щр╡Нр┤Щр╡╛ р┤ор┤▓р┤пр┤╛р┤│р┤В р┤др┤┐р┤░р┤Юр╡Нр┤Юр╡Жр┤Яр╡Бр┤Хр╡Нр┤Хр╡Бр┤Х.",
    "kn": "р▓ир│Ар▓╡р│Б р▓Хр▓ир│Нр▓ир▓б р▓Жр▓пр│Нр▓Хр│Ж р▓ор▓╛р▓бр▓┐р▓Хр│Кр▓Вр▓бр▓┐р▓жр│Нр▓жр│Ар▓░р▓┐.",
    "gu": "ркдркорлЗ ркЧрлБркЬрк░рк╛ркдрлА рккрк╕ркВркж ркХрк░рлА ркЫрлЗ.",
    "or": "рмЖрмкрмг рмУрмбрм╝рм┐рмЖ рмЪрнЯрми рмХрм░рм┐рмЫрмирнНрмдрм┐ред",
    "ks": "╪к┘П┘З┘Ж╪п ┌й╪┤┘Е█М╪▒█М ┘Е┘Ж╪к╪о╪и ┌й█М ┌п╪ж█М █Б█Т█Ф",
    "raj": "рдерд╛рд░реЗ рд░рд╛рдЬрд╕реНрдерд╛рдиреА рдЪреБрдиреА рд╣реИред"
}
speak(confirm_text.get(lang_code, confirm_text["en"]), lang_code)

# --- Main App ---
scraped_text = scrape_sdnbvc()

if st.button("ЁЯОЩ Ask a Question"):
    with st.spinner("Recording..."):
        audio, fs = record_until_silence()
        fd, tmp_path = tempfile.mkstemp(suffix=".wav")
        os.close(fd)
        save_wav(tmp_path, audio, fs)
        query = transcribe_whisper(tmp_path, lang_code)
        os.remove(tmp_path)

        answer = find_answer(query, scraped_text)
        speak(answer, lang_code)

        # Ask for callback
        speak("Would you like a callback?", lang_code)
        audio, fs = record_until_silence()
        fd, tmp_path = tempfile.mkstemp(suffix=".wav")
        os.close(fd)
        save_wav(tmp_path, audio, fs)
        reply = transcribe_whisper(tmp_path, lang_code)
        os.remove(tmp_path)

        if "yes" in reply.lower():
            log_callback_request(query, "9876543210", lang_code)
            confirm_callback(lang_code)
